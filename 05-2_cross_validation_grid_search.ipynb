{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76528d6a-ed14-4cfd-861c-6c5a615e9a0b",
   "metadata": {},
   "source": [
    "Up to now I have been using a single train and test split. That is fine for quick checks, but it can mislead if the split is lucky or unlucky. In this chapter I will create an explicit validation set, then switch to cross-validation. After that I will tune hyperparameters with grid search and randomized search. I will keep the model simple, a decision tree, so I can focus on the evaluation process itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb7c93-f899-42ff-aabc-8d67967500ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d58c29-7d95-4a45-90b2-9187bad4108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "train_test_split, \n",
    "cross_validate, \n",
    "StratifiedKFold, \n",
    "GridSearchCV, \n",
    "RandomizedSearchCV)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1869da-e716-4fee-b72a-95699f7eaa22",
   "metadata": {},
   "source": [
    "# Load data and make a validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd63137-4ce7-40a9-8b85-96752937d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "X = wine[['alcohol', 'sugar', 'pH']]\n",
    "y = wine['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daa5c50-b12b-4b63-a58a-cd46ad16a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  sugar    pH  class\n",
       "0      9.4    1.9  3.51    0.0\n",
       "1      9.8    2.6  3.20    0.0\n",
       "2      9.8    2.3  3.26    0.0\n",
       "3      9.8    1.9  3.16    0.0\n",
       "4      9.4    1.9  3.51    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5a5299-b6e8-427b-8bc3-830b6dfeb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: hold out test set\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1190f9ce-d55e-4b01-83b5-cd3ac15c755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: from the training portion, hold out validation set\n",
    "sub_X, val_X, sub_y, val_y = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7513a887-8e56-46a5-8a02-011480d70cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4157, 3), (1040, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_X.shape, val_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c304c76-8a55-41a8-ab5e-04c400ea0b46",
   "metadata": {},
   "source": [
    "The original train set of 5197 samples has been reduced to 4157 samples, and the validation set has been set to 1040 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b6f2a-087b-4c57-8ed0-a67b0bbb8dba",
   "metadata": {},
   "source": [
    "# Fit a tree on sub-train, evaluate on validation\n",
    "\n",
    "I am not scaling since trees are scale-invariant. The point is to see the train-validation gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4691eb-03ff-459d-bf8f-525823a4216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9971133028626413\n",
      "0.864423076923077\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt.fit(sub_X, sub_y)\n",
    "\n",
    "print(dt.score(sub_X, sub_y))\n",
    "print(dt.score(val_X, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc8a7c-164c-491c-8d0f-3e61e74fdaf4",
   "metadata": {},
   "source": [
    "We can see a very high sub-train score and a lower validation score. That is the usual overfitting pattern for an unpruned tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf90b7c-c8a0-41cb-98e2-21d48d81f855",
   "metadata": {},
   "source": [
    "# Cross-validation on the original train split\n",
    "\n",
    "The validation split is informative, but we want a more stable estimate. Cross-validation averages over multiple folds, which reduces variance from any single split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a12f0fd-e15e-403d-92be-cc50cf0155e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.00510907, 0.00456619, 0.00486827, 0.00455022, 0.00434589]), 'score_time': array([0.00069785, 0.00058079, 0.00063062, 0.00056291, 0.00054502]), 'test_score': array([0.87019231, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}\n",
      "0.8554925223957948\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(dt, train_X, train_y)\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db198975-7fdf-4aaa-965d-0c7ad8a7457c",
   "metadata": {},
   "source": [
    "\"cross_validate\" returns fit_time, score_time and test_score. The last key is the 5 cross validation of 5 folds. By default, cross_validate performs 5-fold cross validation.\n",
    "\n",
    "The mean value of the five values of 'test_score' gives me the cross-validated score. I can also control the splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0fa153-73e8-4641-82be-0619f7e3eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554925223957948\n"
     ]
    }
   ],
   "source": [
    "# Use StratifiedKFold to preserve class balance in each fold\n",
    "\n",
    "scores = cross_validate(dt, train_X, train_y, cv = StratifiedKFold())\n",
    "\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3829bceb-2e52-446b-892c-c4b06b079a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8581873425226026\n"
     ]
    }
   ],
   "source": [
    "# Setting the number of splits and shuffling helps when I want more robustness\n",
    "\n",
    "splitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "scores = cross_validate(dt, train_X, train_y, cv = splitter)\n",
    "\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525d0f9-6063-4418-9bbf-6bb8efca4ed2",
   "metadata": {},
   "source": [
    "The average scores are close across settings, which is a good sign that my estimate is stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b135b-7a99-4a29-b4c1-48f299061561",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Now lets tune a small set of hyperparameters. The first pass will only vary min_impurity_decrease. This is a simple regularizer for trees. I expect very small values to help prune tiny branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf09db-b257-4569-9f67-0dc0242d6a43",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9049f587-28a3-41c1-a7ec-add6d30bd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615162593804117\n",
      "{'min_impurity_decrease': 0.0001}\n",
      "[0.86800067 0.86453617 0.86492226 0.86780891 0.86761605]\n",
      "{'min_impurity_decrease': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "params = {'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state = 42),\n",
    "    params,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "gs.fit(train_X, train_y)\n",
    "\n",
    "dt = gs.best_estimator_\n",
    "\n",
    "print(dt.score(train_X, train_y))\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_['mean_test_score'])\n",
    "print(gs.cv_results_['params'][gs.best_index_]) # check whether best_params_  = params + best_index_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2e366-4aec-43e7-8445-9063541824b8",
   "metadata": {},
   "source": [
    "I can extract the best model and its score on the training split, and also the parameters that performed best during cross-validation.\n",
    "\n",
    "This was a narrow grid. I will expand to include depth and split controls. I will sweep reasonably, not excessively, to keep runtime under control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fac89a9-fa24-49ca-95e7-c30420acc65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'min_impurity_decrease': np.float64(0.0004), 'min_samples_split': 12}\n",
      "0.8683865773302731\n"
     ]
    }
   ],
   "source": [
    "params = {'min_impurity_decrease' : np.arange(0.0001, 0.001, 0.0001),\n",
    "          'max_depth' : range(5, 20, 1),\n",
    "          'min_samples_split' : range(2, 100, 10)\n",
    "         }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state = 42),\n",
    "    params,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "gs.fit(train_X, train_y)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(np.max(gs.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dfd98a-0154-43cf-91bc-26731442c5c6",
   "metadata": {},
   "source": [
    "I keep the best settings, but I still want to confirm on the test set later. For now I will only look at cross-validated means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242e752-bae8-46e7-8281-c263a6d96b46",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "Grid search is exhaustive over a grid. If the search space grows, it becomes expensive or too coarse. Randomized search samples from continuous distributions and finds good regions faster.\n",
    "\n",
    "I will create integer and continuous distributions for the tree controls, which define a parameter distribution for the tree. \n",
    "Note that impurity decrease is a small positive value, depth is moderately large, and sample counts are modest ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb8e4ff-b794-42ab-b397-d8506be03594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 39, 'min_impurity_decrease': np.float64(0.00034102546602601173), 'min_samples_leaf': 7, 'min_samples_split': 13}\n",
      "0.8695428296438884\n"
     ]
    }
   ],
   "source": [
    "params = {'min_impurity_decrease' : uniform(0.0001, 0.001),\n",
    "          'max_depth' : randint(20, 50),\n",
    "          'min_samples_split' : randint(2, 25),\n",
    "          'min_samples_leaf' : randint(1, 25)\n",
    "         }\n",
    "# Run the randomized search. I will use 100 iterations here, which is already plenty for this small dataset.\n",
    "rs = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state = 42),\n",
    "    params,\n",
    "    n_iter = 100,\n",
    "    n_jobs = -1,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "rs.fit(train_X, train_y)\n",
    "\n",
    "print(rs.best_params_)\n",
    "print(np.max(rs.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11903b5d-ef8c-4135-b05f-5f9f68490fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    }
   ],
   "source": [
    "# Now evaluate the best model on the held-out test set.\n",
    "\n",
    "dt = rs.best_estimator_\n",
    "print(dt.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ebdd0-9ee1-4999-ba53-4518bf03bbfa",
   "metadata": {},
   "source": [
    "This tells me how well the chosen configuration generalizes to completely unseen data. I can speculate for a small but real improvement over earlier settings. If the score is similar, that is also fine. Stability matters more than chasing small gains sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa341e3-c022-4fd1-9afe-c0b73119e954",
   "metadata": {},
   "source": [
    "# What I learned\n",
    "\n",
    "Using a single validation split showed clear overfitting on the unpruned tree, but cross-validation gave me a steadier estimate. A small regularization like min_impurity_decrease consistently improved generalization. Grid search worked well for a narrow set of choices, but randomized search was more efficient when I expanded the space to continuous ranges. The final test score did not jump dramatically, which is realistic on a small tabular dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
